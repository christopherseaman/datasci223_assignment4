{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7efb55c",
   "metadata": {},
   "source": [
    "# Part 3: Advanced Analysis\n",
    "\n",
    "This notebook implements advanced analysis techniques for physiological time series data.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "This section sets up the plotting style for consistent visualizations throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23240b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats, signal\n",
    "import pywt\n",
    "import os\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83a848",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Time Domain Features\n",
    "\n",
    "This section implements the function to extract time-domain features from physiological signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_domain_features(data, window_size=60):\n",
    "    \"\"\"Extract time-domain features from physiological signals.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame with columns ['heart_rate', 'eda', 'temperature']\n",
    "        window_size (int): Size of rolling window in seconds\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with time-domain features\n",
    "    \"\"\"\n",
    "    # Make a copy of the data\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Convert timestamp to datetime if present and not already\n",
    "    if 'timestamp' in df.columns and not pd.api.types.is_datetime64_dtype(df['timestamp']):\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Set timestamp as index if present\n",
    "    if 'timestamp' in df.columns:\n",
    "        df = df.set_index('timestamp')\n",
    "    \n",
    "    # Calculate sampling rate and window samples\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        sampling_rate = 1 / df.index.to_series().diff().mean().total_seconds()\n",
    "    else:\n",
    "        sampling_rate = 1.0  # Default to 1 Hz if no timestamp\n",
    "    window_samples = int(window_size * sampling_rate)\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Process heart rate first to get required features\n",
    "    if 'heart_rate' in df.columns:\n",
    "        rolling_hr = df['heart_rate'].rolling(window=window_samples, min_periods=1)\n",
    "        \n",
    "        # Basic statistics (as per test requirements)\n",
    "        features['mean_hr'] = rolling_hr.mean()\n",
    "        features['std_hr'] = rolling_hr.std()\n",
    "        \n",
    "        # Calculate RR intervals (in seconds)\n",
    "        rr_intervals = 60 / df['heart_rate']  # Convert HR to RR intervals\n",
    "        \n",
    "        # RMSSD (Root Mean Square of Successive Differences)\n",
    "        rr_diff = np.diff(rr_intervals)\n",
    "        rmssd = np.sqrt(np.mean(rr_diff ** 2))\n",
    "        features['rmssd'] = pd.Series(rmssd, index=df.index)\n",
    "        \n",
    "        # SDNN (Standard Deviation of NN intervals)\n",
    "        sdnn = np.std(rr_intervals)\n",
    "        features['sdnn'] = pd.Series(sdnn, index=df.index)\n",
    "        \n",
    "        # pNN50 (Percentage of successive RR intervals that differ by more than 50ms)\n",
    "        pnn50 = 100 * np.sum(np.abs(rr_diff) > 0.05) / len(rr_diff)\n",
    "        features['pnn50'] = pd.Series(pnn50, index=df.index)\n",
    "    \n",
    "    # Process all signals for basic features\n",
    "    signals = ['heart_rate', 'eda', 'temperature']\n",
    "    for signal in signals:\n",
    "        if signal not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        rolling = df[signal].rolling(window=window_samples, min_periods=1)\n",
    "        \n",
    "        # Basic statistics (as per test requirements)\n",
    "        if signal != 'heart_rate':  # Already handled for heart rate\n",
    "            features[f'{signal}_mean'] = rolling.mean()\n",
    "            features[f'{signal}_std'] = rolling.std()\n",
    "            features[f'{signal}_min'] = rolling.min()\n",
    "            features[f'{signal}_max'] = rolling.max()\n",
    "        elif signal == 'heart_rate':\n",
    "            # For heart rate, add min/max (mean/std already added above)\n",
    "            features['min'] = rolling.min()\n",
    "            features['max'] = rolling.max()\n",
    "        \n",
    "        # Additional statistics\n",
    "        features[f'{signal}_skew'] = rolling.apply(stats.skew)\n",
    "        features[f'{signal}_kurtosis'] = rolling.apply(stats.kurtosis)\n",
    "        features[f'{signal}_roc'] = df[signal].diff()\n",
    "    \n",
    "    # Create feature DataFrame\n",
    "    feature_df = pd.DataFrame(features, index=df.index)\n",
    "    \n",
    "    # Add back metadata columns if they existed\n",
    "    for col in ['subject_id', 'session']:\n",
    "        if col in df.columns:\n",
    "            feature_df[col] = df[col]\n",
    "    \n",
    "    # Reset index if it was a timestamp\n",
    "    if isinstance(feature_df.index, pd.DatetimeIndex):\n",
    "        feature_df = feature_df.reset_index()\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f280e63",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Frequency Analysis\n",
    "\n",
    "This section implements the function to perform frequency-domain analysis using Welch's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_frequency_components(data, sampling_rate, window_size=60):\n",
    "    \"\"\"Perform frequency-domain analysis using Welch's method.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame with columns ['heart_rate', 'eda', 'temperature']\n",
    "        sampling_rate (float): Sampling rate in Hz\n",
    "        window_size (int): Size of rolling window in seconds\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing frequency components and power spectrum\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    signals = ['heart_rate', 'eda', 'temperature']\n",
    "    \n",
    "    # Define frequency bands\n",
    "    freq_bands = {\n",
    "        'vlf': (0.0033, 0.04),  # Very low frequency\n",
    "        'lf': (0.04, 0.15),     # Low frequency\n",
    "        'hf': (0.15, 0.4)       # High frequency\n",
    "    }\n",
    "    \n",
    "    for sig in signals:\n",
    "        if sig not in data.columns:\n",
    "            continue\n",
    "            \n",
    "        # Get signal data\n",
    "        signal_data = data[sig].dropna().values\n",
    "        \n",
    "        # Calculate power spectral density using Welch's method\n",
    "        frequencies, psd = signal.welch(signal_data, \n",
    "                                      fs=sampling_rate,\n",
    "                                      nperseg=window_size*sampling_rate,\n",
    "                                      noverlap=window_size*sampling_rate//2)\n",
    "        \n",
    "        # Store frequencies and PSD\n",
    "        results[f'{sig}_frequencies'] = frequencies\n",
    "        results[f'{sig}_psd'] = psd\n",
    "        \n",
    "        # Calculate power in each frequency band\n",
    "        for band_name, (low_freq, high_freq) in freq_bands.items():\n",
    "            # Find indices for the frequency band\n",
    "            band_mask = (frequencies >= low_freq) & (frequencies < high_freq)\n",
    "            \n",
    "            # Calculate power in band using trapezoidal integration\n",
    "            band_power = np.trapz(psd[band_mask], frequencies[band_mask])\n",
    "            results[f'{sig}_{band_name}_power'] = band_power\n",
    "        \n",
    "        # Calculate LF/HF ratio\n",
    "        if results[f'{sig}_hf_power'] > 0:\n",
    "            results[f'{sig}_lf_hf_ratio'] = results[f'{sig}_lf_power'] / results[f'{sig}_hf_power']\n",
    "        else:\n",
    "            results[f'{sig}_lf_hf_ratio'] = np.nan\n",
    "    \n",
    "    # Add required outputs\n",
    "    results['frequencies'] = frequencies\n",
    "    results['power'] = psd\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cf3d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Time-Frequency Analysis\n",
    "\n",
    "This section implements the function to perform wavelet-based time-frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9acfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_time_frequency_features(data, sampling_rate, window_size=60):\n",
    "    \"\"\"Perform wavelet-based time-frequency analysis.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame with columns ['heart_rate', 'eda', 'temperature']\n",
    "        sampling_rate (float): Sampling rate in Hz\n",
    "        window_size (int): Size of rolling window in seconds\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing wavelet coefficients and derived features\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    signals = ['heart_rate', 'eda', 'temperature']\n",
    "    \n",
    "    # Define wavelet parameters\n",
    "    wavelet = 'morl'  # Morlet wavelet\n",
    "    num_scales = window_size\n",
    "    \n",
    "    for sig in signals:\n",
    "        if sig not in data.columns:\n",
    "            continue\n",
    "            \n",
    "        # Get signal data\n",
    "        signal_data = data[sig].dropna().values\n",
    "        \n",
    "        # Define scales for wavelet transform\n",
    "        scales = np.arange(1, num_scales + 1)\n",
    "        \n",
    "        # Perform continuous wavelet transform\n",
    "        coeffs, freqs = pywt.cwt(signal_data, scales, wavelet, sampling_period=1/sampling_rate)\n",
    "        \n",
    "        # Store wavelet coefficients and frequencies\n",
    "        results[f'{sig}_wavelet_coeffs'] = coeffs\n",
    "        results[f'{sig}_wavelet_freqs'] = freqs\n",
    "        \n",
    "        # Calculate wavelet-based features\n",
    "        \n",
    "        # Energy distribution\n",
    "        energy = np.abs(coeffs)**2\n",
    "        results[f'{sig}_wavelet_energy'] = np.sum(energy, axis=0)\n",
    "        \n",
    "        # Entropy\n",
    "        normalized_energy = energy / np.sum(energy)\n",
    "        entropy = -np.sum(normalized_energy * np.log2(normalized_energy + 1e-10), axis=0)\n",
    "        results[f'{sig}_wavelet_entropy'] = entropy\n",
    "        \n",
    "        # Scale-averaged wavelet power\n",
    "        results[f'{sig}_wavelet_power'] = np.mean(energy, axis=1)\n",
    "        \n",
    "        # Dominant frequency at each time point\n",
    "        dominant_freqs = freqs[np.argmax(energy, axis=0)]\n",
    "        results[f'{sig}_dominant_freqs'] = dominant_freqs\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f0090d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "Here's an example of how to use these functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example data\n",
    "from part1_exploration import load_data, preprocess_data\n",
    "\n",
    "data_dir = 'data/raw'\n",
    "df = load_data(data_dir)\n",
    "processed_df = preprocess_data(df)\n",
    "\n",
    "if not processed_df.empty:\n",
    "    # Calculate sampling rate\n",
    "    sampling_rate = 1 / processed_df['timestamp'].diff().mean().total_seconds()\n",
    "    \n",
    "    # Extract features for first subject and session\n",
    "    subject_data = processed_df[\n",
    "        (processed_df['subject_id'] == processed_df['subject_id'].iloc[0]) & \n",
    "        (processed_df['session'] == processed_df['session'].iloc[0])\n",
    "    ]\n",
    "    \n",
    "    # Time-domain features\n",
    "    time_features = extract_time_domain_features(subject_data)\n",
    "    print(\"Time-domain features shape:\", time_features.shape)\n",
    "    print(\"\\nTime-domain feature columns:\", time_features.columns.tolist())\n",
    "    \n",
    "    # Frequency components\n",
    "    freq_features = analyze_frequency_components(subject_data, sampling_rate)\n",
    "    print(\"\\nFrequency components:\", list(freq_features.keys()))\n",
    "    \n",
    "    # Time-frequency features\n",
    "    time_freq_features = analyze_time_frequency_features(subject_data, sampling_rate)\n",
    "    print(\"\\nTime-frequency features:\", list(time_freq_features.keys())) "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
